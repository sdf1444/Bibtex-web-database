{"ast":null,"code":"var chevrotain = require('chevrotain');\nvar createToken = chevrotain.createToken;\nvar typeProperty = createToken({\n  name: 'Type',\n  pattern: /@ARTICLE|@BOOK|@INCOLLECTION|@PHDTHESIS|@TECHREPORT|@MISC|@INPROCEEDINGS|@UNPUBLISHED/i\n});\nvar keyProperty = createToken({\n  name: 'Key',\n  pattern: /([a-zA-Z+-]{2,}[0-9]{2,}[a-zA-Z]*)/i\n});\nvar generalProperty = createToken({\n  name: 'Field',\n  pattern: /AUTHOR.*|BOOKTITLE.*|\\bTITLE.*|JOURNAL.*|VOLUME.*|YEAR.*|NUMBER.*|PAGES.*|EDITION.*|PUBLISHER.*|ADDRESS.*|VOLUME.*|SERIES.*|EDITOR.*|NOTE.*|HOWPUBLISHED.*|DOI.*|MONTH.*|URL.*|ORGANIZATION.*/i\n});\nvar sentenceProperty = createToken({\n  name: 'Sentence',\n  pattern: /[a-zA-Z0-9-.]+/i\n});\nvar SelectLexer = new chevrotain.Lexer([typeProperty, keyProperty, generalProperty, sentenceProperty], {\n  positionTracking: 'onlyOffset'\n});\n\n/**\n * @function - Transforms a token vector into JSON\n * @param {vector} Tokens\n * @returns {.json}\n */\n\nvar transformToJSON = function transformToJSON(parsedData) {\n  var bibtexArray = [];\n  var property = '';\n  var item = {};\n  parsedData.tokens.forEach(function (_ref, index) {\n    var image = _ref.image,\n      name = _ref.tokenType.name;\n    if (name === 'Type') {\n      item.type = image.replace(/@/, '');\n    }\n    if (name === 'Key') {\n      item.key = image.replace(/{/, '');\n    }\n    if (name === 'Field') {\n      var str = image.split(/[=]/gm);\n      property = str[0].replace(/[ \\t]+$/, '');\n      item[property] = str[1].replace(/^\\s+/, '');\n      if (parsedData.tokens[index + 1] === undefined || parsedData.tokens[index + 1].tokenType.name === 'Type') {\n        bibtexArray.push(item);\n        item = {};\n        property = '';\n      }\n    }\n    if (name === 'Sentence') {\n      if (parsedData.tokens[index + 1].tokenType.name !== 'Sentence') {\n        item[property] += image;\n      } else {\n        item[property] += \"\".concat(image, \" \");\n      }\n    }\n  });\n  return {\n    total: bibtexArray.length + 1,\n    references: bibtexArray\n  };\n};\n\n/**\n * @function - Cleans the string, tokenizes and returns json\n * @param {string, buffer, URL} path\n * @returns {JSON}\n */\n\nvar parseBibtex = function parseBibtex(data) {\n  var dataString = data.toString();\n  var noComments = dataString.replace(/^%(.*\\n)/gm, '');\n  var typeLine = noComments.replace(/ARTICLE|\\b@BOOK\\b|INCOLLECTION|PHDTHESIS|TECHREPORT|MISC|INPROCEEDINGS/gim, '$&\\n');\n  var doubleDashes = typeLine.replace(/--/gm, '-');\n  var cleansed = doubleDashes.replace(/['*{},\"]/gm, '');\n  var parsedData = SelectLexer.tokenize(cleansed);\n  return transformToJSON(parsedData);\n};\n\n/**\n * @function - Transform JSON into Bibtex\n * @param {JSON}\n * @returns {string}\n */\n\nvar parseToBibtex = function parseToBibtex(data, property) {\n  var bibtex = '';\n  var list = JSON.parse(data);\n  try {\n    list[property].forEach(function (item) {\n      Object.keys(item).forEach(function (key) {\n        switch (key) {\n          case 'type':\n            bibtex += \"@\".concat(item[key]);\n            break;\n          case 'key':\n            bibtex += \"{\".concat(item[key], \",\\n\");\n            break;\n          default:\n            bibtex += \"\".concat(key, \" = \").concat(item[key], \",\\n\");\n        }\n      });\n      bibtex += '}\\n';\n    });\n    return bibtex;\n  } catch (_) {\n    throw new Error('Check the object property is an array or is named correctly');\n  }\n};\nmodule.exports = {\n  parseBibtex: parseBibtex,\n  parseToBibtex: parseToBibtex\n};","map":{"version":3,"names":["chevrotain","require","createToken","typeProperty","name","pattern","keyProperty","generalProperty","sentenceProperty","SelectLexer","Lexer","positionTracking","transformToJSON","parsedData","bibtexArray","property","item","tokens","forEach","index","image","tokenType","type","replace","key","str","split","undefined","push","total","length","references","parseBibtex","data","dataString","toString","noComments","typeLine","doubleDashes","cleansed","tokenize","parseToBibtex","bibtex","list","JSON","parse","Object","keys","_","Error","module","exports"],"sources":["/home/spencer/Personal/Bibtex-web-database-master/client/node_modules/@devisle/reference-js/parsers/bibtexParsers.js"],"sourcesContent":["const chevrotain = require('chevrotain');\n\nconst { createToken } = chevrotain;\n\nconst typeProperty = createToken({\n  name: 'Type',\n  pattern: /@ARTICLE|@BOOK|@INCOLLECTION|@PHDTHESIS|@TECHREPORT|@MISC|@INPROCEEDINGS|@UNPUBLISHED/i,\n});\n\nconst keyProperty = createToken({\n  name: 'Key',\n  pattern: /([a-zA-Z+-]{2,}[0-9]{2,}[a-zA-Z]*)/i,\n});\n\nconst generalProperty = createToken({\n  name: 'Field',\n  pattern: /AUTHOR.*|BOOKTITLE.*|\\bTITLE.*|JOURNAL.*|VOLUME.*|YEAR.*|NUMBER.*|PAGES.*|EDITION.*|PUBLISHER.*|ADDRESS.*|VOLUME.*|SERIES.*|EDITOR.*|NOTE.*|HOWPUBLISHED.*|DOI.*|MONTH.*|URL.*|ORGANIZATION.*/i,\n});\n\nconst sentenceProperty = createToken({\n  name: 'Sentence',\n  pattern: /[a-zA-Z0-9-.]+/i,\n});\n\nconst SelectLexer = new chevrotain.Lexer(\n  [typeProperty, keyProperty, generalProperty, sentenceProperty],\n  {\n    positionTracking: 'onlyOffset',\n  },\n);\n\n/**\n * @function - Transforms a token vector into JSON\n * @param {vector} Tokens\n * @returns {.json}\n */\n\nconst transformToJSON = (parsedData) => {\n  const bibtexArray = [];\n  let property = '';\n  let item = {};\n\n  parsedData.tokens.forEach(({ image, tokenType: { name } }, index) => {\n    if (name === 'Type') {\n      item.type = image.replace(/@/, '');\n    }\n\n    if (name === 'Key') {\n      item.key = image.replace(/{/, '');\n    }\n\n    if (name === 'Field') {\n      const str = image.split(/[=]/gm);\n      property = str[0].replace(/[ \\t]+$/, '');\n      item[property] = str[1].replace(/^\\s+/, '');\n\n      if (\n        parsedData.tokens[index + 1] === undefined\n        || parsedData.tokens[index + 1].tokenType.name === 'Type'\n      ) {\n        bibtexArray.push(item);\n        item = {};\n        property = '';\n      }\n    }\n\n    if (name === 'Sentence') {\n      if (parsedData.tokens[index + 1].tokenType.name !== 'Sentence') {\n        item[property] += image;\n      } else {\n        item[property] += `${image} `;\n      }\n    }\n  });\n\n  return {\n    total: bibtexArray.length + 1,\n    references: bibtexArray,\n  };\n};\n\n/**\n * @function - Cleans the string, tokenizes and returns json\n * @param {string, buffer, URL} path\n * @returns {JSON}\n */\n\nconst parseBibtex = (data) => {\n  const dataString = data.toString();\n  const noComments = dataString.replace(/^%(.*\\n)/gm, '');\n  const typeLine = noComments.replace(\n    /ARTICLE|\\b@BOOK\\b|INCOLLECTION|PHDTHESIS|TECHREPORT|MISC|INPROCEEDINGS/gim,\n    '$&\\n',\n  );\n  const doubleDashes = typeLine.replace(/--/gm, '-');\n  const cleansed = doubleDashes.replace(/['*{},\"]/gm, '');\n  const parsedData = SelectLexer.tokenize(cleansed);\n\n  return transformToJSON(parsedData);\n};\n\n/**\n * @function - Transform JSON into Bibtex\n * @param {JSON}\n * @returns {string}\n */\n\nconst parseToBibtex = (data, property) => {\n  let bibtex = '';\n  const list = JSON.parse(data);\n  try {\n    list[property].forEach((item) => {\n      Object.keys(item).forEach((key) => {\n        switch (key) {\n          case 'type':\n            bibtex += `@${item[key]}`;\n            break;\n          case 'key':\n            bibtex += `{${item[key]},\\n`;\n            break;\n          default:\n            bibtex += `${key} = ${item[key]},\\n`;\n        }\n      });\n      bibtex += '}\\n';\n    });\n\n    return bibtex;\n  } catch (_) {\n    throw new Error('Check the object property is an array or is named correctly');\n  }\n};\n\nmodule.exports = {\n  parseBibtex,\n  parseToBibtex,\n};\n"],"mappings":"AAAA,IAAMA,UAAU,GAAGC,OAAO,CAAC,YAAY,CAAC;AAExC,IAAQC,WAAW,GAAKF,UAAU,CAA1BE,WAAW;AAEnB,IAAMC,YAAY,GAAGD,WAAW,CAAC;EAC/BE,IAAI,EAAE,MAAM;EACZC,OAAO,EAAE;AACX,CAAC,CAAC;AAEF,IAAMC,WAAW,GAAGJ,WAAW,CAAC;EAC9BE,IAAI,EAAE,KAAK;EACXC,OAAO,EAAE;AACX,CAAC,CAAC;AAEF,IAAME,eAAe,GAAGL,WAAW,CAAC;EAClCE,IAAI,EAAE,OAAO;EACbC,OAAO,EAAE;AACX,CAAC,CAAC;AAEF,IAAMG,gBAAgB,GAAGN,WAAW,CAAC;EACnCE,IAAI,EAAE,UAAU;EAChBC,OAAO,EAAE;AACX,CAAC,CAAC;AAEF,IAAMI,WAAW,GAAG,IAAIT,UAAU,CAACU,KAAK,CACtC,CAACP,YAAY,EAAEG,WAAW,EAAEC,eAAe,EAAEC,gBAAgB,CAAC,EAC9D;EACEG,gBAAgB,EAAE;AACpB,CAAC,CACF;;AAED;AACA;AACA;AACA;AACA;;AAEA,IAAMC,eAAe,GAAG,SAAlBA,eAAe,CAAIC,UAAU,EAAK;EACtC,IAAMC,WAAW,GAAG,EAAE;EACtB,IAAIC,QAAQ,GAAG,EAAE;EACjB,IAAIC,IAAI,GAAG,CAAC,CAAC;EAEbH,UAAU,CAACI,MAAM,CAACC,OAAO,CAAC,gBAAiCC,KAAK,EAAK;IAAA,IAAxCC,KAAK,QAALA,KAAK;MAAehB,IAAI,QAAjBiB,SAAS,CAAIjB,IAAI;IACnD,IAAIA,IAAI,KAAK,MAAM,EAAE;MACnBY,IAAI,CAACM,IAAI,GAAGF,KAAK,CAACG,OAAO,CAAC,GAAG,EAAE,EAAE,CAAC;IACpC;IAEA,IAAInB,IAAI,KAAK,KAAK,EAAE;MAClBY,IAAI,CAACQ,GAAG,GAAGJ,KAAK,CAACG,OAAO,CAAC,GAAG,EAAE,EAAE,CAAC;IACnC;IAEA,IAAInB,IAAI,KAAK,OAAO,EAAE;MACpB,IAAMqB,GAAG,GAAGL,KAAK,CAACM,KAAK,CAAC,OAAO,CAAC;MAChCX,QAAQ,GAAGU,GAAG,CAAC,CAAC,CAAC,CAACF,OAAO,CAAC,SAAS,EAAE,EAAE,CAAC;MACxCP,IAAI,CAACD,QAAQ,CAAC,GAAGU,GAAG,CAAC,CAAC,CAAC,CAACF,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC;MAE3C,IACEV,UAAU,CAACI,MAAM,CAACE,KAAK,GAAG,CAAC,CAAC,KAAKQ,SAAS,IACvCd,UAAU,CAACI,MAAM,CAACE,KAAK,GAAG,CAAC,CAAC,CAACE,SAAS,CAACjB,IAAI,KAAK,MAAM,EACzD;QACAU,WAAW,CAACc,IAAI,CAACZ,IAAI,CAAC;QACtBA,IAAI,GAAG,CAAC,CAAC;QACTD,QAAQ,GAAG,EAAE;MACf;IACF;IAEA,IAAIX,IAAI,KAAK,UAAU,EAAE;MACvB,IAAIS,UAAU,CAACI,MAAM,CAACE,KAAK,GAAG,CAAC,CAAC,CAACE,SAAS,CAACjB,IAAI,KAAK,UAAU,EAAE;QAC9DY,IAAI,CAACD,QAAQ,CAAC,IAAIK,KAAK;MACzB,CAAC,MAAM;QACLJ,IAAI,CAACD,QAAQ,CAAC,cAAOK,KAAK,MAAG;MAC/B;IACF;EACF,CAAC,CAAC;EAEF,OAAO;IACLS,KAAK,EAAEf,WAAW,CAACgB,MAAM,GAAG,CAAC;IAC7BC,UAAU,EAAEjB;EACd,CAAC;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA,IAAMkB,WAAW,GAAG,SAAdA,WAAW,CAAIC,IAAI,EAAK;EAC5B,IAAMC,UAAU,GAAGD,IAAI,CAACE,QAAQ,EAAE;EAClC,IAAMC,UAAU,GAAGF,UAAU,CAACX,OAAO,CAAC,YAAY,EAAE,EAAE,CAAC;EACvD,IAAMc,QAAQ,GAAGD,UAAU,CAACb,OAAO,CACjC,2EAA2E,EAC3E,MAAM,CACP;EACD,IAAMe,YAAY,GAAGD,QAAQ,CAACd,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC;EAClD,IAAMgB,QAAQ,GAAGD,YAAY,CAACf,OAAO,CAAC,YAAY,EAAE,EAAE,CAAC;EACvD,IAAMV,UAAU,GAAGJ,WAAW,CAAC+B,QAAQ,CAACD,QAAQ,CAAC;EAEjD,OAAO3B,eAAe,CAACC,UAAU,CAAC;AACpC,CAAC;;AAED;AACA;AACA;AACA;AACA;;AAEA,IAAM4B,aAAa,GAAG,SAAhBA,aAAa,CAAIR,IAAI,EAAElB,QAAQ,EAAK;EACxC,IAAI2B,MAAM,GAAG,EAAE;EACf,IAAMC,IAAI,GAAGC,IAAI,CAACC,KAAK,CAACZ,IAAI,CAAC;EAC7B,IAAI;IACFU,IAAI,CAAC5B,QAAQ,CAAC,CAACG,OAAO,CAAC,UAACF,IAAI,EAAK;MAC/B8B,MAAM,CAACC,IAAI,CAAC/B,IAAI,CAAC,CAACE,OAAO,CAAC,UAACM,GAAG,EAAK;QACjC,QAAQA,GAAG;UACT,KAAK,MAAM;YACTkB,MAAM,eAAQ1B,IAAI,CAACQ,GAAG,CAAC,CAAE;YACzB;UACF,KAAK,KAAK;YACRkB,MAAM,eAAQ1B,IAAI,CAACQ,GAAG,CAAC,QAAK;YAC5B;UACF;YACEkB,MAAM,cAAOlB,GAAG,gBAAMR,IAAI,CAACQ,GAAG,CAAC,QAAK;QAAC;MAE3C,CAAC,CAAC;MACFkB,MAAM,IAAI,KAAK;IACjB,CAAC,CAAC;IAEF,OAAOA,MAAM;EACf,CAAC,CAAC,OAAOM,CAAC,EAAE;IACV,MAAM,IAAIC,KAAK,CAAC,6DAA6D,CAAC;EAChF;AACF,CAAC;AAEDC,MAAM,CAACC,OAAO,GAAG;EACfnB,WAAW,EAAXA,WAAW;EACXS,aAAa,EAAbA;AACF,CAAC"},"metadata":{},"sourceType":"script"}